// generated by polka.codes
// Label-based x86_64 JIT compilation for PolkaVM
// Single-pass compilation with lazy label creation for maximum performance

#include "helper.hh"
#include "jit_label_manager.hh"
#include "jit_control_flow.hh"
#include "a64_helper.hh"
#include "opcodes.hh"
#include <asmjit/asmjit.h>
#include <cstddef>
#include <cstdint>
#include <cstring>
#include <stdio.h>
#include <vector>
#include <unordered_map>
#include <mutex>
#include <memory>

using namespace asmjit;
using namespace asmjit::x86;
using namespace JIT;
using namespace PVM;

// Global storage for dispatcher jump tables
// Maps function pointer -> dispatcher table
static std::unordered_map<void*, std::pair<void**, size_t>> s_dispatcherTables;
static std::mutex s_dispatcherTablesMutex;

// Export function to get dispatcher table for a function
extern "C" void* _Nullable * _Nullable getDispatcherTable(void* _Nonnull funcPtr, size_t* _Nonnull outSize) noexcept {
    std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);
    auto it = s_dispatcherTables.find(funcPtr);
    if (it != s_dispatcherTables.end()) {
        *outSize = it->second.second;
        return it->second.first;
    }
    *outSize = 0;
    return nullptr;
}

// Export function to set dispatcher table for a function (called from Swift)
extern "C" void setDispatcherTable(void* _Nonnull funcPtr, void* _Nullable * _Nullable table, size_t size) noexcept {
    std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);
    s_dispatcherTables[funcPtr] = {table, size};
}

// External declaration for the instruction emitter
extern "C" bool jit_emitter_emit_basic_block_instructions(
    void* _Nonnull assembler,
    const char* _Nonnull target_arch,
    const uint8_t* _Nonnull bytecode,
    uint32_t start_pc,
    uint32_t end_pc);

// Helper to get instruction size
static uint32_t getInstructionSize(const uint8_t* bytecode, uint32_t pc, size_t bytecode_size) {
    return get_instruction_size(bytecode, pc, bytecode_size);
}

// Helper to extract jump target from instruction
static uint32_t getJumpTarget(const uint8_t* bytecode, uint32_t pc, uint32_t instrSize) {
    if (instrSize == 5 || instrSize == 7) {
        // Jump (5 bytes): [opcode][offset_32bit]
        // Branch (7 bytes): [opcode][reg1][reg2][offset_32bit]
        uint32_t offset;
        if (instrSize == 5) {
            memcpy(&offset, &bytecode[pc + 1], 4);
        } else {
            memcpy(&offset, &bytecode[pc + 3], 4);
        }
        return pc + instrSize + int32_t(offset);
    }
    return pc + instrSize; // Fallthrough
}

// Main compilation function with labels
extern "C" int32_t compilePolkaVMCode_x64_labeled(
    const uint8_t* _Nonnull codeBuffer,
    size_t codeSize,
    uint32_t initialPC,
    uint32_t jitMemorySize,
    void* _Nullable * _Nonnull funcOut)
{
    // Validate inputs
    if (!codeBuffer || codeSize == 0) {
        return 1; // Invalid input
    }

    if (!funcOut) {
        return 2; // Invalid output parameter
    }

    // Initialize asmjit runtime
    static JitRuntime runtime;
    CodeHolder code;
    code.init(runtime.environment());

    // Create x86 assembler
    x86::Assembler a(&code);

    // Prologue: save callee-saved registers
    a.push(rbx);
    a.push(rbp);
    a.push(r12);
    a.push(r13);
    a.push(r14);
    a.push(r15);

    // Setup VM environment registers
    a.mov(rbx, rdi);  // registers_ptr -> rbx
    a.mov(r12, rsi);  // memory_base_ptr -> r12
    a.mov(r13d, edx); // memory_size -> r13d
    a.mov(r14, rcx);  // gas_ptr -> r14
    a.mov(r15d, r8d); // initial_pvm_pc -> r15d (PC)
    a.mov(rbp, r9);   // invocation_context_ptr -> rbp

    // Create label manager
    LabelManager labelManager;

    // We'll build the dispatcher table after compilation, using labels that get created
    // during the normal compilation process (via labelManager)

    // Create exit labels for different exit conditions
    Label exitLabel = a.new_label();       // Normal exit (halt) - eax = 0
    Label panicLabel = a.new_label();      // Panic exit (trap, address < 65536) - eax = -1
    Label pagefaultLabel = a.new_label();  // Page fault exit (address >= memory_size) - eax = 3
    Label outOfGasLabel = a.new_label();   // Out of gas exit - eax = 1
    Label unsupportedLabel = a.new_label();// Unsupported instruction - exit to interpreter - eax = 2
    Label dispatcherLoop = a.new_label();  // Dispatcher loop for indirect jumps without jump table
    Label epilogueLabel = a.new_label();   // Epilogue (restore registers and return)

    // Pass the PC label map to labelManager for use during compilation
    // We'll store it separately and use it to build the dispatcher jump table

    // === PRE-PASS: Identify all jump targets ===
    // This is necessary to handle backward jumps (loops)
    // Also check if we need dispatcher table (has JumpInd without jump table support)
    bool needsDispatcherTable = false;
    uint32_t pc = 0;
    while (pc < codeSize) {
        uint8_t opcode = codeBuffer[pc];
        uint32_t instrSize = getInstructionSize(codeBuffer, pc, codeSize);

        if (instrSize == 0) {
            // Unknown opcode - compilation error
            return 3; // Compilation error
        }

        // Check if this code has JumpInd (which needs dispatcher)
        if (opcode_is(opcode, Opcode::JumpInd)) {
            needsDispatcherTable = true;
        }

        // Mark jump targets for control flow instructions
        if (opcode_is(opcode, Opcode::Jump)) {
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize);
            labelManager.markJumpTarget(targetPC);
        } else if (opcode_is(opcode, Opcode::BranchEq) ||
                   opcode_is(opcode, Opcode::BranchNe)) {
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize);
            labelManager.markJumpTarget(targetPC);
        } else if (opcode_is(opcode, Opcode::LoadImmJump)) {
            uint8_t destReg = codeBuffer[pc + 1];
            uint32_t jumpOffset;
            memcpy(&jumpOffset, &codeBuffer[pc + 2], 4);   // Jump offset is at bytes 2-5
            uint32_t targetPC = pc + instrSize + int32_t(jumpOffset);
            labelManager.markJumpTarget(targetPC);
        }

        pc += instrSize;
    }

    // === GAS ACCOUNTING HELPER ===
    // Lambda to deduct gas and check for exhaustion
    // Returns true if gas was deducted successfully, false if out of gas
    auto deductGas = [&](uint64_t gasCost) -> void {
        // Load current gas value from r14 (VM_GAS_PTR)
        a.mov(x86::rax, x86::qword_ptr(x86::r14));
        // Subtract gas cost (sets CF if borrow/underflow occurred)
        a.sub(x86::rax, gasCost);
        // Store updated value back (preserves flags)
        a.mov(x86::qword_ptr(x86::r14), x86::rax);
        // Jump if borrow occurred (unsigned underflow)
        a.jb(outOfGasLabel);
    };

    // === MAIN COMPILATION PASS ===
    pc = 0;
    std::vector<uint32_t> compiledPCs;

    while (pc < codeSize) {
        uint8_t opcode = codeBuffer[pc];
        uint32_t instrSize = getInstructionSize(codeBuffer, pc, codeSize);

        if (instrSize == 0) {
            // Unknown opcode - compilation error
            return 3; // Compilation error
        }

        // Bind label for this PC if:
        // 1. It's a jump target (for branches/jumps)
        // 2. OR we need a dispatcher table (for JumpInd to work)
        // This ensures the dispatcher table has entries for all valid PCs
        if (labelManager.isMarkedTarget(pc) || labelManager.isJumpTarget(pc)) {
            labelManager.bindLabel(&a, pc, "x86_64");
        } else if (needsDispatcherTable) {
            // For dispatcher table, we need labels for ALL instruction PCs
            // This allows JumpInd to jump to any PC without falling back to interpreter
            labelManager.bindLabel(&a, pc, "x86_64");
        }

        // === GAS ACCOUNTING ===
        // Deduct 1 gas for this instruction (default gas cost per PVM spec)
        // Check AFTER binding labels so jump targets don't double-deduct
        deductGas(1);

        // Handle control flow instructions with labels
        if (opcode_is(opcode, Opcode::Jump)) {
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize);
            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "x86_64");
            jit_emit_jump_labeled(&a, "x86_64", targetLabel);
            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::BranchEq)) {
            uint8_t reg1 = codeBuffer[pc + 1];
            uint8_t reg2 = codeBuffer[pc + 2];
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize);

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "x86_64");
            jit_emit_branch_eq_labeled(&a, "x86_64", reg1, reg2, targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::BranchNe)) {
            uint8_t reg1 = codeBuffer[pc + 1];
            uint8_t reg2 = codeBuffer[pc + 2];
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize);

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "x86_64");
            jit_emit_branch_ne_labeled(&a, "x86_64", reg1, reg2, targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::LoadImmJump)) {
            uint8_t destReg = codeBuffer[pc + 1];
            uint32_t jumpOffset;
            uint32_t immediate;
            memcpy(&jumpOffset, &codeBuffer[pc + 2], 4);   // Jump offset is at bytes 2-5
            memcpy(&immediate, &codeBuffer[pc + 6], 4);    // Immediate value is at bytes 6-9
            uint32_t targetPC = pc + instrSize + int32_t(jumpOffset);

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "x86_64");
            jit_emit_load_imm_jump_labeled(&a, "x86_64", destReg, immediate, targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::JumpInd)) {
            // JumpInd: [opcode][reg_index] - jump to address stored in register
            uint8_t ptr_reg = codeBuffer[pc + 1];

            // Load target address from register
            a.mov(x86::eax, x86::dword_ptr(x86::rbx, ptr_reg * 8));

            // Special case: check for halt address (0xFFFFFFFF)
            // This is the djumpHaltAddress constant
            a.cmp(x86::eax, 0xFFFFFFFF);
            a.je(exitLabel);  // Jump to halt exit

            // Check if jump table is available
            a.mov(x86::rdx, x86::qword_ptr(x86::rbp, offsetof(JITHostFunctionTable, jumpTableData)));
            a.test(x86::rdx, x86::rdx);
            a.jz(dispatcherLoop);  // No jump table, use dispatcher loop instead

            // Load jump table parameters
            a.mov(x86::ecx, x86::dword_ptr(x86::rbp, offsetof(JITHostFunctionTable, alignmentFactor)));
            a.mov(x86::r8d, x86::dword_ptr(x86::rbp, offsetof(JITHostFunctionTable, jumpTableEntrySize)));
            a.mov(x86::r9d, x86::dword_ptr(x86::rbp, offsetof(JITHostFunctionTable, jumpTableEntriesCount)));

            // Validate target != 0
            a.test(x86::eax, x86::eax);
            a.jz(pagefaultLabel);  // Invalid target (0)

            // Validate target alignment
            a.mov(x86::r10d, x86::eax);  // Copy target
            a.test(x86::ecx, x86::ecx);  // Check if alignmentFactor is 0
            a.jz(pagefaultLabel);  // Division by zero is invalid
            a.mov(x86::edx, 0);   // Clear edx for division
            a.div(x86::ecx);  // Divide by alignmentFactor, quotient in eax, remainder in edx
            a.cmp(x86::edx, 0);  // Check if remainder is 0 (aligned)
            a.jne(pagefaultLabel);  // Not aligned, invalid jump

            // Calculate entry index: (target / alignmentFactor) - 1
            a.dec(x86::eax);  // Decrement to get entry index
            a.cmp(x86::eax, x86::r9d);  // Compare with entriesCount
            a.jae(pagefaultLabel);  // Index >= entriesCount, invalid jump

            // Calculate byte offset: entryIndex * entrySize
            a.mov(x86::edx, x86::eax);  // Copy entry index
            a.imul(x86::edx, x86::r8d);  // Multiply by entry size

            // Load jump table data pointer
            a.mov(x86::r11, x86::qword_ptr(x86::rbp, offsetof(JITHostFunctionTable, jumpTableData)));

            // Read entry based on entrySize
            // For now, support entry sizes 1, 2, 3, 4
            Label entrySize1 = a.new_label();
            Label entrySize2 = a.new_label();
            Label entrySize3 = a.new_label();
            Label entrySize4 = a.new_label();
            Label readDone = a.new_label();

            a.cmp(x86::r8d, 1);
            a.je(entrySize1);
            a.cmp(x86::r8d, 2);
            a.je(entrySize2);
            a.cmp(x86::r8d, 3);
            a.je(entrySize3);
            a.cmp(x86::r8d, 4);
            a.je(entrySize4);
            // Invalid entry size, fall back to interpreter
            a.jmp(unsupportedLabel);

            // Entry size 1: Read UInt8
            a.bind(entrySize1);
            a.movzx(x86::eax, x86::byte_ptr(x86::r11, x86::rdx));
            a.jmp(readDone);

            // Entry size 2: Read UInt16
            a.bind(entrySize2);
            a.movzx(x86::eax, x86::word_ptr(x86::r11, x86::rdx));
            a.jmp(readDone);

            // Entry size 3: Read UInt24
            a.bind(entrySize3);
            a.movzx(x86::eax, x86::byte_ptr(x86::r11, x86::rdx));  // Read byte 0
            a.mov(x86::r10d, x86::eax);  // Save byte 0
            // Read bytes 1-2: [r11 + rdx + 1] using base + index + displacement
            // Format: [base + index*scale + displacement]
            a.movzx(x86::eax, x86::word_ptr(x86::r11, x86::rdx, 0, 1));  // Read bytes 1-2
            a.shl(x86::eax, 8);  // Shift to make room for byte 0
            a.or_(x86::eax, x86::r10d);  // Combine byte 0
            a.jmp(readDone);

            // Entry size 4: Read UInt32
            a.bind(entrySize4);
            a.mov(x86::eax, x86::dword_ptr(x86::r11, x86::rdx));
            a.jmp(readDone);

            a.bind(readDone);

            // Update PC with the looked-up address
            a.mov(x86::r15d, x86::eax);

            // Jump to the new PC
            // First, check if the new PC is within valid range
            a.cmp(x86::eax, codeSize);
            a.jae(pagefaultLabel);  // PC out of bounds

            // For now, fall back to interpreter with the updated PC
            // This is safe because the jump table lookup validated the target
            a.mov(x86::eax, 2);  // Exit code 2 = exit to interpreter with updated PC
            a.jmp(epilogueLabel);

            pc += instrSize;
            continue;
        }

        // === Ecalli (Host Call) ===
        // Ecalli format: [opcode][call_index_32bit] = 5 bytes
        if (opcode == 10) {  // Ecalli opcode is 10
            // Extract call_index from instruction bytes
            uint32_t call_index;
            memcpy(&call_index, &codeBuffer[pc + 1], 4);

            // Emit host call using the pvm_host_call_trampoline
            // x86_64 calling convention:
            // rdi = context (rbp), rsi = func_idx, rdx = registers (rbx),
            // rcx = memory (r12), r8d = memory_size (r13d), r9 = gas (r14)
            a.mov(x86::rdi, x86::rbp);      // context pointer
            a.mov(x86::rsi, call_index);    // function index
            a.mov(x86::rdx, x86::rbx);      // registers pointer
            a.mov(x86::rcx, x86::r12);      // memory pointer
            a.mov(x86::r8d, x86::r13d);     // memory size
            a.mov(x86::r9, x86::r14);       // gas pointer

            // Call the trampoline
            a.mov(x86::rax, reinterpret_cast<uint64_t>(&pvm_host_call_trampoline));
            a.call(x86::rax);

            // Check result (eax contains error code or return value)
            // Any value >= 0xFFFF_FFFA is an error (hostRequestedHalt, pageFault, gasExhausted,
            // internalError, hostFunctionNotFound, hostFunctionThrewError, etc.)
            a.cmp(x86::eax, 0xFFFFFFFA);
            // Jump directly to epilogue to preserve error code in eax
            // This allows specific error codes to propagate:
            // - 0xFFFFFFFA (4294967290) = hostRequestedHalt
            // - 0xFFFFFFFB (4294967291) = pageFault
            // - 0xFFFFFFFC (4294967292) = gasExhausted
            // - 0xFFFFFFFD (4294967293) = internalError
            // - 0xFFFFFFFE (4294967294) = hostFunctionNotFound
            // - 0xFFFFFFFF (4294967295) = hostFunctionThrewError
            a.jae(epilogueLabel);  // Jump if above or equal (error range) - preserves eax

            // Store result in R0
            a.mov(x86::qword_ptr(x86::rbx, 0), x86::rax);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::Trap)) {
            // Set return value to -1 (trap) in eax, then jump to epilogue
            a.mov(x86::eax, -1);
            a.jmp(epilogueLabel);
            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::Halt)) {
            // Jump to exit
            a.jmp(exitLabel);
            pc += instrSize;
            continue;
        }

        // === Division Instructions with Zero-Check ===
        // Division by zero causes hardware exception - must check explicitly
        // Format: [opcode][dest_reg][src_reg] = 3 bytes
        if (opcode_is(opcode, Opcode::DivU32) ||
            opcode_is(opcode, Opcode::DivS32) ||
            opcode_is(opcode, Opcode::RemU32) ||
            opcode_is(opcode, Opcode::RemS32) ||
            opcode_is(opcode, Opcode::DivU64) ||
            opcode_is(opcode, Opcode::DivS64) ||
            opcode_is(opcode, Opcode::RemU64) ||
            opcode_is(opcode, Opcode::RemS64)) {
            // Decode instruction: [opcode][dest_reg][src_reg]
            uint8_t dest_reg = codeBuffer[pc + 1];
            uint8_t src_reg = codeBuffer[pc + 2];

            // Load divisor into ecx for check
            a.mov(x86::rcx, x86::qword_ptr(x86::rbx, src_reg * 8));

            // Check if divisor is zero
            a.test(x86::rcx, x86::rcx);  // Fast way to check if rcx == 0
            a.jz(panicLabel);  // If zero, jump to panic (division by zero)

            // Not zero - proceed with division using dispatcher
            if (!jit_emitter_emit_basic_block_instructions(&a, "x86_64", codeBuffer, pc, pc + instrSize)) {
                return 3; // Compilation error
            }

            pc += instrSize;
            continue;
        }

        // === Load Instructions with Bounds Checking ===
        // PVM Spec: addresses < 2^16 (65536) → panic, addresses >= memory_size → page fault
        if (opcode_is(opcode, Opcode::LoadU8) ||
            opcode_is(opcode, Opcode::LoadI8) ||
            opcode_is(opcode, Opcode::LoadU16) ||
            opcode_is(opcode, Opcode::LoadI16) ||
            opcode_is(opcode, Opcode::LoadU32) ||
            opcode_is(opcode, Opcode::LoadI32) ||
            opcode_is(opcode, Opcode::LoadU64)) {
            // Decode instruction: [opcode][dest_reg][ptr_reg][offset_16bit]
            uint8_t dest_reg = codeBuffer[pc + 1];
            uint8_t ptr_reg = codeBuffer[pc + 2];
            int16_t offset;
            memcpy(&offset, &codeBuffer[pc + 3], 2);

            // Load pointer register into rax
            a.mov(x86::rax, x86::qword_ptr(x86::rbx, ptr_reg * 8));

            // Add offset to get final address (sign-extended 32-bit immediate)
            a.add(x86::rax, int32_t(offset));

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // If we get here, address is valid - inline the load instruction
            // Load from memory into register, then store to VM register
            // IMPORTANT: Use movzx for unsigned loads to avoid rcx corruption
            // (rcx was used for bounds checking and still contains memory_size)
            x86::Mem mem(x86::r12, x86::rax, 0, 0);

            if (opcode_is(opcode, Opcode::LoadU8)) {
                a.movzx(x86::ecx, mem);  // Zero-extend to avoid rcx corruption
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadI8)) {
                a.movsx(x86::rcx, mem);  // Sign-extend is fine for signed loads
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadU16)) {
                a.movzx(x86::ecx, mem);  // Zero-extend to avoid rcx corruption
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadI16)) {
                a.movsx(x86::rcx, mem);  // Sign-extend is fine for signed loads
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadU32)) {
                a.mov(x86::ecx, mem);  // 32-bit mov zero-extends automatically
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadI32)) {
                a.movsxd(x86::rcx, mem);  // Sign-extend is fine for signed loads
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            } else if (opcode_is(opcode, Opcode::LoadU64)) {
                a.mov(x86::rcx, mem);  // 64-bit load, no corruption possible
                a.mov(x86::qword_ptr(x86::rbx, dest_reg * 8), x86::rcx);
            }

            pc += instrSize;
            continue;
        }

        // === Store Instructions with Bounds Checking ===
        if (opcode_is(opcode, Opcode::StoreU8) ||
            opcode_is(opcode, Opcode::StoreU16) ||
            opcode_is(opcode, Opcode::StoreU32) ||
            opcode_is(opcode, Opcode::StoreU64)) {
            // Decode instruction: [opcode][ptr_reg][src_reg][offset_16bit]
            uint8_t ptr_reg = codeBuffer[pc + 1];
            uint8_t src_reg = codeBuffer[pc + 2];
            int16_t offset;
            memcpy(&offset, &codeBuffer[pc + 3], 2);

            // Load pointer register into rax
            a.mov(x86::rax, x86::qword_ptr(x86::rbx, ptr_reg * 8));

            // Add offset to get final address (sign-extended 32-bit immediate)
            a.add(x86::rax, int32_t(offset));

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // If we get here, address is valid - inline the store instruction
            // Load value from VM register, then store to memory
            a.mov(x86::rdx, x86::qword_ptr(x86::rbx, src_reg * 8));  // Load source value

            // Use Mem::build() to create [r12 + rax] addressing mode
            x86::Mem mem(x86::r12, x86::rax, 0, 0);

            if (opcode_is(opcode, Opcode::StoreU8)) {
                a.mov(mem, x86::dl);
            } else if (opcode_is(opcode, Opcode::StoreU16)) {
                a.mov(mem, x86::dx);
            } else if (opcode_is(opcode, Opcode::StoreU32)) {
                a.mov(mem, x86::edx);
            } else if (opcode_is(opcode, Opcode::StoreU64)) {
                a.mov(mem, x86::rdx);
            }

            pc += instrSize;
            continue;
        }

        // === StoreImm Instructions with Bounds Checking ===
        // PVM Spec: addresses < 2^16 (65536) → panic, addresses >= memory_size → page fault
        // Format: [opcode][value_Xbit][address_32bit]
        if (opcode_is(opcode, Opcode::StoreImmU8)) {
            // StoreImmU8: [opcode][value_8bit][address_32bit] = 6 bytes
            uint8_t value = codeBuffer[pc + 1];
            uint32_t address;
            memcpy(&address, &codeBuffer[pc + 2], 4);

            // Load address into eax for bounds checking
            a.mov(x86::eax, address);

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // Store value to memory
            a.mov(x86::cl, value);
            x86::Mem mem(x86::r12, x86::rax, 0, 0);
            a.mov(mem, x86::cl);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU16)) {
            // StoreImmU16: [opcode][value_16bit][address_32bit] = 7 bytes
            uint16_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 2);
            memcpy(&address, &codeBuffer[pc + 3], 4);

            // Load address into eax for bounds checking
            a.mov(x86::eax, address);

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // Store value to memory
            a.mov(x86::cx, value);
            x86::Mem mem(x86::r12, x86::rax, 0, 0);
            a.mov(mem, x86::cx);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU32)) {
            // StoreImmU32: [opcode][value_32bit][address_32bit] = 9 bytes
            uint32_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 4);
            memcpy(&address, &codeBuffer[pc + 5], 4);

            // Load address into eax for bounds checking
            a.mov(x86::eax, address);

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // Store value to memory
            a.mov(x86::ecx, value);
            x86::Mem mem(x86::r12, x86::rax, 0, 0);
            a.mov(mem, x86::ecx);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU64)) {
            // StoreImmU64: [opcode][value_64bit][address_32bit] = 13 bytes
            uint64_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 8);
            memcpy(&address, &codeBuffer[pc + 9], 4);

            // Load address into eax for bounds checking
            a.mov(x86::eax, address);

            // Bounds check: address < 65536 → panic
            a.cmp(x86::rax, 65536);
            a.jb(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(x86::ecx, x86::r13d);  // Load memory_size into ecx
            a.cmp(x86::rax, x86::rcx);
            a.jae(pagefaultLabel);

            // Store value to memory
            a.mov(x86::rcx, value);
            x86::Mem mem(x86::r12, x86::rax, 0, 0);
            a.mov(mem, x86::rcx);

            pc += instrSize;
            continue;
        }

        // For all other instructions, use the existing dispatcher
        // but only for this single instruction
        if (!jit_emitter_emit_basic_block_instructions(&a, "x86_64", codeBuffer, pc, pc + instrSize)) {
            return 3; // Compilation error
        }

        pc += instrSize;
    }

    // Bind panic label
    a.bind(panicLabel);
    a.mov(x86::eax, -1);  // Exit code -1 = panic(.trap)
    a.jmp(epilogueLabel);

    // Bind pagefault label
    // Note: Faulting address should be in eax (from bounds checking code)
    // Save it to VM register R0 before setting exit code
    a.bind(pagefaultLabel);
    a.mov(x86::qword_ptr(x86::rbx, 0), x86::rax);  // Save faulting address to VM R0
    a.mov(x86::eax, 3);   // Exit code 3 = pageFault
    a.jmp(epilogueLabel);

    // Bind out-of-gas label
    a.bind(outOfGasLabel);
    a.mov(x86::eax, 1);   // Exit code 1 = outOfGas
    a.jmp(epilogueLabel);

    // Bind unsupported label
    a.bind(unsupportedLabel);
    a.mov(x86::eax, 2);   // Exit code 2 = fallback to interpreter
    a.jmp(epilogueLabel);

    // Bind exit label
    a.bind(exitLabel);

    // Set return value to 0 (halt) in eax
    a.xor_(x86::eax, x86::eax);
    // Fall through to epilogue

    // Bind epilogue label (for Trap - already has eax=-1 set)
    a.bind(epilogueLabel);

    // Epilogue: restore callee-saved registers and return
    a.pop(r15);
    a.pop(r14);
    a.pop(r13);
    a.pop(r12);
    a.pop(rbp);
    a.pop(rbx);
    a.ret();

    // === DISPATCHER LOOP FOR INDIRECT JUMPS WITHOUT JUMP TABLE ===
    // This is used by JumpInd when no jump table is provided
    // It implements a computed goto using a jump table built at compile time
    // NOTE: This must come AFTER the epilogue/ret so normal execution can't reach it
    a.bind(dispatcherLoop);

    // Validate PC is within bounds
    a.cmp(x86::r15d, static_cast<uint32_t>(codeSize));
    a.jae(pagefaultLabel);  // PC out of bounds

    // Load the jump table base address from the context
    // The jump table is stored in JITHostFunctionTable.dispatcherJumpTable
    a.mov(x86::rdx, x86::qword_ptr(x86::rbp, offsetof(JITHostFunctionTable, dispatcherJumpTable)));
    a.test(x86::rdx, x86::rdx);
    a.jz(unsupportedLabel);  // No dispatcher table - fall back to interpreter

    // Jump table entry size = 8 bytes (pointer)
    // Calculate offset: PC * 8
    a.mov(x86::eax, x86::r15d);  // Load PC
    a.shl(x86::rax, 3);  // Multiply by 8 (pointer size)
    a.add(x86::rdx, x86::rax);  // Add to base

    // Load target address from jump table
    a.mov(x86::rax, x86::qword_ptr(x86::rdx));

    // Jump to the target address
    a.test(x86::rax, x86::rax);  // Check if address is null
    a.jz(unsupportedLabel);  // Null entry - fall back to interpreter
    a.jmp(x86::rax);
    // NOTE: Execution never returns here - either jumps to target or falls back

    // Generate the function code
    Error err = runtime.add(funcOut, &code);
    if (err != Error::kOk) {
        return int32_t(err);
    }

    // Build dispatcher jump table ONLY if needed (has JumpInd instructions)
    // This allows JumpInd to work without a PVM jump table
    if (needsDispatcherTable) {
        // OPTIMIZATION: Create dispatcher entries for ALL instruction PCs
        // This eliminates interpreter fallbacks for JumpInd to any PC
        // Previously we only created entries for jump targets, causing fallback

        // Get all PCs that have labels (now includes ALL instruction PCs when needsDispatcherTable is true)
        std::vector<uint32_t> labeledPCs = labelManager.getAllPCs();

        // Allocate table (one entry per possible PC, initialized to null)
        auto dispatcherTable = std::make_unique<void*[]>(codeSize);
        std::memset(dispatcherTable.get(), 0, codeSize * sizeof(void*));

        // Get the base address of the generated function
        uint8_t* funcBase = reinterpret_cast<uint8_t*>(*funcOut);

        // Resolve label addresses and populate the jump table
        for (uint32_t pc : labeledPCs) {
            // CRITICAL: Bounds check to prevent heap buffer overflow
            // labeledPCs may contain out-of-bounds values from markJumpTarget
            if (pc >= codeSize) {
                // Skip out-of-bounds PC values silently
                continue;
            }

            Label label = labelManager.getLabel(pc);
            if (!label.is_valid()) {
                continue;  // Skip invalid labels
            }

            // Get the address of this label from the CodeHolder
            const asmjit::LabelEntry& label_entry = code.label_entry_of(label);
            uint64_t offset = label_entry.offset();
            dispatcherTable[pc] = funcBase + offset;
        }

        // Store the dispatcher table in global map for later retrieval
        {
            std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);
            // Transfer ownership to global storage
            void** tablePtr = dispatcherTable.release();
            s_dispatcherTables[*funcOut] = {tablePtr, static_cast<size_t>(codeSize)};
        }
    }

    return 0; // Success
}

// ============================================================================
// MARK: - Export/Import API for Persistent Caching
// ============================================================================

/// Export compiled code metadata for serialization
/// Returns information needed to serialize compiled code
///
/// NOTE: This is a simplified version that returns basic metadata
/// Full code serialization would require deeper AsmJit integration
///
/// @param funcPtr Compiled function pointer from compilePolkaVMCode_x64_labeled
/// @param dispatcherTableOut Output: dispatcher table pointer (if exists)
/// @param dispatcherTableSizeOut Output: size of dispatcher table in entries
/// @param hasDispatcherTableOut Output: 1 if function has dispatcher table, 0 otherwise
/// @return 0 on success, error code on failure
extern "C" int32_t getCompiledCodeInfo(
    void* _Nonnull funcPtr,
    void* _Nullable * _Nullable * _Nonnull dispatcherTableOut,
    size_t* _Nonnull dispatcherTableSizeOut,
    int* _Nonnull hasDispatcherTableOut) noexcept
{
    if (!funcPtr || !dispatcherTableOut || !dispatcherTableSizeOut || !hasDispatcherTableOut) {
        return -1;  // Invalid parameters
    }

    std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);
    auto it = s_dispatcherTables.find(funcPtr);

    if (it != s_dispatcherTables.end()) {
        // Function has a dispatcher table
        *dispatcherTableOut = it->second.first;
        *dispatcherTableSizeOut = it->second.second;
        *hasDispatcherTableOut = 1;
    } else {
        // Function doesn't have a dispatcher table (no JumpInd)
        *dispatcherTableOut = nullptr;
        *dispatcherTableSizeOut = 0;
        *hasDispatcherTableOut = 0;
    }

    return 0;  // Success
}

/// Store compiled code metadata for a function
/// This allows tracking which bytecode corresponds to which compiled function
///
/// @param bytecodeHash Hash of the bytecode (for cache key)
/// @param funcPtr Compiled function pointer
/// @param codeSize Size of the compiled code in bytes (if known)
/// @return 0 on success, error code on failure
extern "C" int32_t setCompiledCodeMetadata(
    uint64_t bytecodeHash,
    void* _Nonnull funcPtr,
    size_t codeSize) noexcept
{
    if (!funcPtr) {
        return -1;  // Invalid parameter
    }

    // For now, this is a placeholder
    // In a full implementation, we would store this mapping in a global cache
    // This allows looking up functions by bytecode hash later

    return 0;  // Success
}

// ============================================================================
// MARK: - Memory Management (Dispatcher Table Cleanup)
// ============================================================================

/// Free the dispatcher table associated with a JIT-compiled function (x64 version)
/// This prevents memory leaks from accumulating dispatcher tables
///
/// @param funcPtr Function pointer returned by compilePolkaVMCode_x64_labeled
/// @note Safe to call with nullptr or function pointers that don't have tables
extern "C" void freeDispatcherTable_x64(void* _Nullable funcPtr) noexcept {
    if (!funcPtr) {
        return;  // Nothing to free
    }

    std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);
    auto it = s_dispatcherTables.find(funcPtr);

    if (it != s_dispatcherTables.end()) {
        // Free the dispatcher table array
        void** table = it->second.first;
        delete[] table;

        // Remove from map
        s_dispatcherTables.erase(it);

        #ifdef DEBUG_JIT
        fprintf(stderr, "[JIT x64] Freed dispatcher table for function %p\n", funcPtr);
        #endif
    } else {
        #ifdef DEBUG_JIT
        fprintf(stderr, "[JIT x64] Warning: No dispatcher table for function %p\n", funcPtr);
        #endif
    }
}

/// Free ALL dispatcher tables (x64 version)
/// Useful for process cleanup or memory pressure situations
///
/// @note This frees all global dispatcher table storage
extern "C" void freeAllDispatcherTables_x64() noexcept {
    std::lock_guard<std::mutex> lock(s_dispatcherTablesMutex);

    for (auto& entry : s_dispatcherTables) {
        void** table = entry.second.first;
        delete[] table;
    }

    size_t count = s_dispatcherTables.size();
    s_dispatcherTables.clear();

    #ifdef DEBUG_JIT
    fprintf(stderr, "[JIT x64] Freed %zu dispatcher tables\n", count);
    #endif
}
