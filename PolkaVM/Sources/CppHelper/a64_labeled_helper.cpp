// generated by polka.codes
// Label-based AArch64 JIT compilation for PolkaVM
// Single-pass compilation with lazy label creation for maximum performance

#include "helper.hh"
#include "jit_label_manager.hh"
#include "jit_control_flow.hh"
#include "opcodes.hh"
#include <asmjit/a64.h>
#include <asmjit/asmjit.h>
#include <cstddef>
#include <cstdint>
#include <cstring>
#include <stdio.h>
#include <vector>

using namespace asmjit;
using namespace asmjit::a64;
using namespace JIT;
using namespace PVM;

// External declaration for the instruction emitter
extern "C" bool jit_emitter_emit_basic_block_instructions(
    void* _Nonnull assembler,
    const char* _Nonnull target_arch,
    const uint8_t* _Nonnull bytecode,
    uint32_t start_pc,
    uint32_t end_pc);

// Helper to get instruction size
static uint32_t getInstructionSize(const uint8_t* bytecode, uint32_t pc, size_t bytecode_size) {
    return get_instruction_size(bytecode, pc, bytecode_size);
}

// Helper to extract jump target from instruction
// Returns the target PC for branch instructions, or fallthrough PC for non-branches
static uint32_t getJumpTarget(const uint8_t* bytecode, uint32_t pc, uint32_t instrSize, size_t bytecodeSize) {
    uint8_t opcode = bytecode[pc];

    // Jump (5 bytes): [opcode][offset_32bit]
    if (instrSize == 5 && opcode_is(opcode, Opcode::Jump)) {
        if (pc + 5 > bytecodeSize) {
            fprintf(stderr, "[JIT] Jump instruction truncated at PC %u (need 5 bytes, have %zu)\n", pc, bytecodeSize);
            return pc + instrSize;
        }
        uint32_t offset;
        memcpy(&offset, &bytecode[pc + 1], 4);
        return pc + int32_t(offset);
    }

    // Branch register instructions (7 bytes): [opcode][reg1][reg2][offset_32bit]
    // BranchEq, BranchNe, BranchLtU, BranchLtS, BranchGeU, BranchGeS
    if (instrSize == 7) {
        if (pc + 7 > bytecodeSize) {
            fprintf(stderr, "[JIT] Branch instruction truncated at PC %u (need 7 bytes, have %zu)\n", pc, bytecodeSize);
            return pc + instrSize;
        }
        uint32_t offset;
        memcpy(&offset, &bytecode[pc + 3], 4);
        return pc + int32_t(offset);
    }

    // Branch immediate instructions (14 bytes): [opcode][reg_index][value_64bit][offset_32bit]
    // BranchEqImm, BranchNeImm, BranchLtUImm, BranchLeUImm, BranchGeUImm, BranchGtUImm,
    // BranchLtSImm, BranchLeSImm, BranchGeSImm, BranchGtSImm
    if (instrSize == 14) {
        if (pc + 14 > bytecodeSize) {
            fprintf(stderr, "[JIT] BranchImm instruction truncated at PC %u (need 14 bytes, have %zu)\n", pc, bytecodeSize);
            return pc + instrSize;
        }
        uint32_t offset;
        memcpy(&offset, &bytecode[pc + 10], 4);  // Offset starts at byte 10
        return pc + int32_t(offset);
    }

    // LoadImmJump: [opcode][r_A | l_X][immed_X (l_X bytes)][immed_Y (l_Y bytes)]
    // CRITICAL: Use actual instruction size (from skip table) to calculate l_Y
    // Format: [opcode][r_A|l_X][immed_X (l_X bytes)][immed_Y (l_Y bytes)]
    // Size = 2 + l_X + l_Y, therefore: l_Y = instrSize - 2 - l_X
    if (opcode_is(opcode, Opcode::LoadImmJump)) {
        if (pc + 1 >= bytecodeSize) return pc + instrSize;

        uint8_t byte1 = bytecode[pc + 1];
        uint32_t l_X = (byte1 >> 4) & 0x07;  // Length of immed_X (bits 4-6)
        if (l_X > 4) l_X = 4;

        // CRITICAL: Calculate l_Y from actual instruction size (instrSize parameter)
        // This matches the main compilation loop and ensures consistency
        uint32_t l_Y = instrSize - 2 - l_X;

        // Validate l_Y is in valid range (0-4 per spec)
        if (l_Y > 4 || (instrSize < 2 + l_X)) {
            // Invalid instruction, return fallthrough
            return pc + instrSize;
        }

        // Check bounds before reading offset
        uint32_t offsetPos = pc + 2 + l_X;
        if (offsetPos + l_Y > bytecodeSize) {
            fprintf(stderr, "[JIT ARM64] LoadImmJump offset truncated at PC %u\n", pc);
            return pc + instrSize;
        }

        // Read offset (little-endian)
        uint32_t offset = 0;
        if (l_Y > 0) {
            for (uint32_t i = 0; i < l_Y && i < 4; i++) {
                offset |= (uint32_t)bytecode[offsetPos + i] << (8 * i);
            }
            // Sign-extend if needed
            if (l_Y < 4) {
                uint32_t signBit = 1U << (l_Y * 8 - 1);
                if (offset & signBit) {
                    offset |= (~0U) << (l_Y * 8);
                }
            }
        }

        return pc + int32_t(offset);
    }

    return pc + instrSize; // Fallthrough
}

// Varint decoder for variable-length integer encoding
// Returns the decoded value and updates out_size to include varint bytes
// CRITICAL: Will return 0 and set out_size to 0 if max_size is exceeded (invalid varint)
static uint64_t decode_varint(const uint8_t* bytecode, uint32_t offset, uint32_t max_size, uint32_t& out_size) {
    uint64_t result = 0;
    uint32_t shift = 0;
    uint32_t i = 0;

    while (true) {
        // CRITICAL: Bounds check to prevent out-of-bounds read
        if (offset + i >= max_size) {
            // Unterminated varint (e.g., 0x80 at last byte) or malformed
            out_size = 0;
            return 0;
        }

        uint8_t byte = bytecode[offset + i];
        result |= (uint64_t(byte & 0x7F)) << shift;
        i++;
        if ((byte & 0x80) == 0) {
            break;
        }
        shift += 7;
        if (shift >= 64) {
            // Varint too large, return 0
            out_size = 1;
            return 0;
        }
    }

    out_size = i;
    return result;
}

// Main compilation function with labels for ARM64
extern "C" int32_t compilePolkaVMCode_a64_labeled(
    void* _Nonnull context,
    const uint8_t* _Nonnull codeBuffer,
    size_t codeSize,
    uint32_t initialPC,
    uint32_t jitMemorySize,
    const uint32_t* _Nullable skipTable,
    size_t skipTableSize,
    const uint8_t* _Nullable bitmask,
    size_t bitmaskSize,
    void* _Nullable * _Nonnull funcOut)
{
    auto* ctx = static_cast<RuntimeContext*>(context);

    // Validate inputs
    if (!codeBuffer || codeSize == 0) {
        return 1; // Invalid input
    }

    if (!funcOut) {
        return 2; // Invalid output parameter
    }

    // Helper lambda to check if a PC is at an instruction boundary using bitmask
    // Per spec pvm.tex, instruction boundaries have bitmask bit 0 set
    auto isInstructionBoundary = [&](uint32_t pc) -> bool {
        if (!bitmask || pc >= codeSize) {
            return false;
        }
        uint32_t byteIndex = pc / 8;
        uint32_t bitIndex = pc % 8;
        if (byteIndex >= bitmaskSize) {
            return false;
        }
        return (bitmask[byteIndex] & (1 << bitIndex)) != 0;
    };

    // Create lambda to get instruction size using skip table
    // This is the authoritative source for variable-length encoded instructions
    auto getInstrSize = [&](uint32_t pc) -> uint32_t {
        uint8_t opcode = codeBuffer[pc];

        // For fixed-size instructions, ignore skip table and use known size
        // This prevents corrupted/inconsistent skip tables from breaking compilation
        uint32_t fixedSize = getInstructionSize(codeBuffer, pc, codeSize);
        if (fixedSize > 0 && fixedSize <= 16) {
            // Fixed-size instruction - use calculated size, not skip table
            return fixedSize;
        }

        // For variable-length instructions, use skip table
        if (skipTable != nullptr && pc < skipTableSize) {
            uint32_t skip = skipTable[pc];

            // CRITICAL: Validate skip won't cause buffer overflow
            // skip is additional bytes beyond opcode, so pc + skip + 1 must be <= codeSize
            if (pc + skip + 1 > codeSize) {
                // Invalid skip value - log and fall back to fixed-size calculation
                uint32_t maxSkip = codeSize - pc - 1;
                fprintf(stderr, "[JIT ARM64] Invalid skip value %u at PC %u (max: %u), using fallback\n",
                        skip, pc, maxSkip);
                return getInstructionSize(codeBuffer, pc, codeSize);
            }

            return skip + 1;  // skip is additional bytes, +1 for opcode
        }

        // Fallback to fixed-size calculation (for safety)
        return getInstructionSize(codeBuffer, pc, codeSize);
    };

    // Use the runtime from the context (owned by Swift)
    CodeHolder code;
    Error err = code.init(ctx->runtime->environment());
    if (err != kErrorOk) {
        fprintf(stderr, "[JIT ARM64] Failed to initialize CodeHolder: %d\n", err);
        return int32_t(err);
    }

    // Validate runtime state before creating assembler
    if (!ctx->runtime) {
        fprintf(stderr, "[JIT ARM64] Runtime context is null\n");
        return 5; // Compilation error
    }

    // Create ARM64 assembler
    a64::Assembler a(&code);

    // Prologue: save callee-saved registers
    // ARM64 callee-saved: x19-x28, x29 (fp), x30 (lr)
    a.sub(a64::sp, a64::sp, 16 * 10); // Allocate stack space
    a.stp(x19, x20, ptr(a64::sp, 0));
    a.stp(x21, x22, ptr(a64::sp, 16));
    a.stp(x23, x24, ptr(a64::sp, 32));
    a.stp(x25, x26, ptr(a64::sp, 48));
    a.stp(x27, x28, ptr(a64::sp, 64));
    a.stp(x29, x30, ptr(a64::sp, 80));

    // Setup VM environment registers (per AArch64 ABI)
    // x0 = registers_ptr, x1 = memory_base_ptr, w2 = memory_size
    // x3 = gas_ptr, w4 = initial_pvm_pc, x5 = invocation_context_ptr
    a.mov(a64::x19, a64::x0);  // registers_ptr -> x19
    a.mov(a64::x20, a64::x1);  // memory_base_ptr -> x20
    a.mov(a64::w21, a64::w2);  // memory_size -> w21
    a.mov(a64::x22, a64::x3);  // gas_ptr -> x22
    a.mov(a64::w23, a64::w4);  // initial_pvm_pc -> w23 (PC)
    a.mov(a64::x24, a64::x5);  // invocation_context_ptr -> x24

    // Create label manager
    LabelManager labelManager;

    // Create exit labels for different exit conditions
    Label exitLabel = a.new_label();       // Normal exit (halt) - w0 = 0
    Label panicLabel = a.new_label();      // Panic exit (trap, address < 65536) - w0 = -1
    Label pagefaultLabel = a.new_label();  // Page fault exit (address >= memory_size) - w0 = 3
    Label outOfGasLabel = a.new_label();   // Out of gas exit - w0 = 1
    Label unsupportedLabel = a.new_label();// Unsupported instruction - exit to interpreter - w0 = 2
    Label epilogueLabel = a.new_label();   // Epilogue (restore registers and return)

    // === PRE-PASS: Identify all jump targets ===
    // This is necessary to handle backward jumps (loops)
    uint32_t pc = 0;
    while (pc < codeSize) {
        uint8_t opcode = codeBuffer[pc];
        uint32_t instrSize = getInstrSize(pc);  // Now handles fixed-size correctly

        if (instrSize == 0) {
            // Unknown opcode - skip and treat as data
            // This can happen when the bitmask marks data as an instruction boundary
            fprintf(stderr, "[JIT ARM64] Unknown opcode at PC %u, treating as data\n", pc);
            pc++;
            continue;
        }

        // Mark jump targets for all control flow instructions
        // This is necessary to handle backward jumps (loops) correctly
        // Only call getJumpTarget for actual branch/jump opcodes to avoid misinterpreting data
        bool isBranchInstruction = opcode_is(opcode, Opcode::Jump) ||
                                   (instrSize == 7) ||  // Branch register instructions
                                   (instrSize == 14) || // Branch immediate instructions
                                   opcode_is(opcode, Opcode::LoadImmJump) ||
                                   opcode_is(opcode, Opcode::LoadImmJumpInd);

        if (isBranchInstruction) {
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize, codeSize);
            if (targetPC != pc + instrSize) {
                // This is a branch/jump instruction (not a fallthrough)
                // VALIDATE: Check if target is at an instruction boundary
                if (targetPC >= codeSize) {
                    fprintf(stderr, "[JIT ARM64] Invalid branch target: PC=%u is beyond code size %zu\n", targetPC, codeSize);
                    // CRITICAL: Skip this invalid jump instead of failing compilation
                    fprintf(stderr, "[JIT ARM64] Skipping invalid jump at PC %u (treating as data)\n", pc);
                    pc += instrSize;
                    continue;
                }
                if (bitmask && !isInstructionBoundary(targetPC)) {
                    fprintf(stderr, "[JIT ARM64] Invalid branch target: PC=%u is not at instruction boundary\n", targetPC);
                    // CRITICAL: Skip this invalid jump instead of failing compilation
                    fprintf(stderr, "[JIT ARM64] Skipping invalid jump at PC %u (treating as data)\n", pc);
                    pc += instrSize;
                    continue;
                }
                labelManager.markJumpTarget(targetPC);
            }
        }

        pc += instrSize;
    }

    // === MAIN COMPILATION PASS ===
    pc = 0;

    // === GAS ACCOUNTING HELPER ===
    // Lambda to deduct gas and check for exhaustion
    auto deductGas = [&](uint64_t gasCost) -> void {
        // Load current gas value from x22 (VM_GAS_PTR)
        a.ldr(a64::x0, a64::ptr(a64::x22));
        // Subtract gas cost and set flags
        a.subs(x0, x0, gasCost);
        // Store updated value back (does not affect flags)
        a.str(x0, a64::ptr(a64::x22));
        // Jump if borrow occurred (unsigned underflow)
        a.b_lo(outOfGasLabel);
    };

    while (pc < codeSize) {
        uint8_t opcode = codeBuffer[pc];
        uint32_t instrSize = getInstrSize(pc);  // Now handles fixed-size correctly

        if (instrSize == 0) {
            // Unknown opcode - skip and treat as data
            // This can happen when the bitmask marks data as an instruction boundary
            fprintf(stderr, "[JIT ARM64] Unknown opcode at PC %u, treating as data\n", pc);
            pc++;
            continue;
        }

        // Check if this PC is a jump target (from pre-pass or previous branch)
        // Bind label here if so
        if (labelManager.isMarkedTarget(pc) || labelManager.isJumpTarget(pc)) {
            labelManager.bindLabel(&a, pc, "aarch64");
        }

        // === GAS ACCOUNTING ===
        // Deduct 1 gas for this instruction (default gas cost per PVM spec)
        // Check AFTER binding labels so jump targets don't double-deduct
        deductGas(1);

        // Handle control flow instructions with labels
        if (opcode_is(opcode, Opcode::Jump)) {
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize, codeSize);
            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "aarch64");
            jit_emit_jump_labeled(&a, "aarch64", targetLabel);
            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::BranchEq)) {
            uint8_t reg1 = codeBuffer[pc + 1];
            uint8_t reg2 = codeBuffer[pc + 2];
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize, codeSize);

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "aarch64");
            jit_emit_branch_eq_labeled(&a, "aarch64", reg1, reg2, targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::BranchNe)) {
            uint8_t reg1 = codeBuffer[pc + 1];
            uint8_t reg2 = codeBuffer[pc + 2];
            uint32_t targetPC = getJumpTarget(codeBuffer, pc, instrSize, codeSize);

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "aarch64");
            jit_emit_branch_ne_labeled(&a, "aarch64", reg1, reg2, targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::LoadImmJump)) {
            // Per spec pvm.tex section 5.10: [opcode][r_A | l_X][immed_X (l_X bytes)][immed_Y (l_Y bytes)]
            uint8_t byte1 = codeBuffer[pc + 1];
            uint8_t destReg = byte1 & 0x0F;  // r_A (lower 4 bits)
            uint32_t l_X = (byte1 >> 4) & 0x07;  // Length of immed_X (bits 4-6)

            // Safety: limit l_X to reasonable range
            if (l_X > 4) l_X = 4;

            // CRITICAL: Calculate l_Y from actual instruction size (from skip table)
            // Format: [opcode][r_A|l_X][immed_X (l_X bytes)][immed_Y (l_Y bytes)]
            // Size = 2 + l_X + l_Y, therefore: l_Y = instrSize - 2 - l_X
            uint32_t l_Y = instrSize - 2 - l_X;

            // Validate l_Y is in valid range (0-4 per spec)
            if (l_Y > 4 || (instrSize < 2 + l_X)) {
                fprintf(stderr, "[JIT ARM64] Invalid LoadImmJump at PC %u: l_X=%u, l_Y=%u, instrSize=%u (skiptable=%u)\n",
                        pc, l_X, l_Y, instrSize, skipTable ? skipTable[pc] : 0);
                return 3; // Compilation error
            }

            // Decode immed_X (l_X bytes, little-endian)
            uint64_t immediate = 0;
            for (uint32_t i = 0; i < l_X; i++) {
                if (pc + 2 + i >= codeSize) return 3;  // Bounds check
                immediate |= (uint64_t)codeBuffer[pc + 2 + i] << (8 * i);
            }
            // Sign-extend if needed
            if (l_X > 0 && l_X < 8) {
                uint64_t signBit = 1ULL << (l_X * 8 - 1);
                if (immediate & signBit) {
                    immediate |= (~0ULL) << (l_X * 8);
                }
            }

            // Decode immed_Y (jump offset, l_Y bytes)
            uint64_t jumpOffset = 0;
            for (uint32_t i = 0; i < l_Y; i++) {
                if (pc + 2 + l_X + i >= codeSize) return 3;  // Bounds check
                jumpOffset |= (uint64_t)codeBuffer[pc + 2 + l_X + i] << (8 * i);
            }
            // Sign-extend offset
            if (l_Y > 0 && l_Y < 8) {
                uint64_t signBit = 1ULL << (l_Y * 8 - 1);
                if (jumpOffset & signBit) {
                    jumpOffset |= (~0ULL) << (l_Y * 8);
                }
            }

            uint32_t targetPC = pc + uint32_t(int32_t(jumpOffset));  // Offset is relative

            Label targetLabel = labelManager.getOrCreateLabel(&a, targetPC, "aarch64");
            jit_emit_load_imm_jump_labeled(&a, "aarch64", destReg, uint32_t(immediate), targetLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::JumpInd)) {
            // JumpInd: [opcode][reg_index] - jump to address stored in register
            uint8_t ptr_reg = codeBuffer[pc + 1];

            // Load target address from register
            a.ldr(a64::w0, a64::ptr(a64::x19, ptr_reg * 8));

            // Special case: check for halt address (0xFFFF0000)
            // This is the djumpHaltAddress constant from Instructions+Helpers.swift
            a.mov(a64::w1, 0xFFFF0000);
            a.cmp(a64::w0, a64::w1);
            a.b_eq(exitLabel);  // Jump to halt exit

            // Check if jump table is available
            a.ldr(a64::x1, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableData)));
            a.cbz(a64::x1, unsupportedLabel);  // No jump table, fall back to interpreter

            // Load jump table parameters
            a.ldr(a64::w2, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, alignmentFactor)));
            a.ldr(a64::w3, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableEntrySize)));
            a.ldr(a64::w4, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableEntriesCount)));

            // Validate target != 0
            a.cbz(a64::w0, pagefaultLabel);  // Invalid target (0)

            // Validate target alignment
            // Calculate entry index: (target / alignmentFactor) - 1
            a.udiv(a64::w5, a64::w0, a64::w2);  // w5 = target / alignmentFactor
            a.msub(a64::w6, a64::w5, a64::w2, a64::w0);  // w6 = remainder = target - (w5 * w2)
            a.cbnz(a64::w6, pagefaultLabel);  // Remainder != 0, not aligned, invalid jump

            // Decrement to get entry index
            a.sub(a64::w5, a64::w5, 1);

            // Check if entry index is within bounds
            a.cmp(a64::w5, a64::w4);
            a.b_hs(pagefaultLabel);  // Index >= entriesCount, invalid jump

            // Calculate byte offset: entryIndex * entrySize
            a.mul(a64::w6, a64::w5, a64::w3);  // w6 = entryIndex * entrySize

            // Load jump table data pointer
            a.ldr(a64::x7, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableData)));

            // Read entry based on entrySize
            // For now, support entry sizes 1, 2, 3, 4
            Label entrySize1 = a.new_label();
            Label entrySize2 = a.new_label();
            Label entrySize3 = a.new_label();
            Label entrySize4 = a.new_label();
            Label readDone = a.new_label();

            a.cmp(a64::w3, 1);
            a.b_eq(entrySize1);
            a.cmp(a64::w3, 2);
            a.b_eq(entrySize2);
            a.cmp(a64::w3, 3);
            a.b_eq(entrySize3);
            a.cmp(a64::w3, 4);
            a.b_eq(entrySize4);
            // Invalid entry size, fall back to interpreter
            a.b(unsupportedLabel);

            // Entry size 1: Read UInt8
            a.bind(entrySize1);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrb(a64::w0, a64::ptr(a64::x8));  // Load byte
            a.b(readDone);

            // Entry size 2: Read UInt16
            a.bind(entrySize2);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrh(a64::w0, a64::ptr(a64::x8));  // Load halfword
            a.b(readDone);

            // Entry size 3: Read UInt24
            a.bind(entrySize3);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrb(a64::w0, a64::ptr(a64::x8));  // Load byte at offset 0
            a.ldrh(a64::w1, a64::ptr(a64::x8, 1));  // Load halfword at offset 1
            a.bfi(a64::w0, a64::w1, 8, 16);  // Insert w1 into w0 at bit 8
            a.b(readDone);

            // Entry size 4: Read UInt32
            a.bind(entrySize4);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldr(a64::w0, a64::ptr(a64::x8));  // Load word
            a.b(readDone);

            a.bind(readDone);

            // Update PC with the looked-up address
            a.mov(a64::w23, a64::w0);

            // Jump to the new PC
            // First, check if the new PC is within valid range
            a.cmp(a64::w0, codeSize);
            a.b_hs(pagefaultLabel);  // PC out of bounds

            // For now, fall back to interpreter with the updated PC
            // This is safe because the jump table lookup validated the target
            a.mov(a64::w0, 2);  // Exit code 2 = exit to interpreter with updated PC
            a.b(epilogueLabel);

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::LoadImmJumpInd)) {
            // LoadImmJumpInd: [opcode][ra_rb_packed][value_byte][offset_byte]
            // ra = dest register (bits 0-3 of byte 1)
            // rb = base register (bits 4-7 of byte 1)
            // Note: This is a simplified format using 1-byte values
            uint8_t packed_regs = codeBuffer[pc + 1];
            uint8_t dest_reg = packed_regs & 0x0F;  // bits 0-3
            uint8_t base_reg = (packed_regs >> 4) & 0x0F;  // bits 4-7

            uint8_t value = codeBuffer[pc + 2];
            uint8_t offset = codeBuffer[pc + 3];

            // Load immediate value into dest register
            a.mov(a64::w0, value);
            a.str(a64::w0, a64::ptr(a64::x19, dest_reg * 8));

            // Load base register value
            a.ldr(a64::w0, a64::ptr(a64::x19, base_reg * 8));

            // Calculate target = base + offset
            a.add(a64::w0, a64::w0, offset);

            // Check for halt address (0xFFFF0000)
            // This is the djumpHaltAddress constant from Instructions+Helpers.swift
            a.mov(a64::w1, 0xFFFF0000);
            a.cmp(a64::w0, a64::w1);
            a.b_eq(exitLabel);  // Jump to halt exit

            // Check if jump table is available
            a.ldr(a64::x1, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableData)));
            a.cbz(a64::x1, unsupportedLabel);  // No jump table, fall back to interpreter

            // Load jump table parameters
            a.ldr(a64::w2, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, alignmentFactor)));
            a.ldr(a64::w3, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableEntrySize)));
            a.ldr(a64::w4, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableEntriesCount)));

            // Validate target != 0
            a.cbz(a64::w0, pagefaultLabel);  // Invalid target (0)

            // Validate target alignment
            // Calculate entry index: (target / alignmentFactor) - 1
            a.udiv(a64::w5, a64::w0, a64::w2);  // w5 = target / alignmentFactor
            a.msub(a64::w6, a64::w5, a64::w2, a64::w0);  // w6 = remainder = target - (w5 * w2)
            a.cbnz(a64::w6, pagefaultLabel);  // Remainder != 0, not aligned, invalid jump

            // Decrement to get entry index
            a.sub(a64::w5, a64::w5, 1);

            // Check if entry index is within bounds
            a.cmp(a64::w5, a64::w4);
            a.b_hs(pagefaultLabel);  // Index >= entriesCount, invalid jump

            // Calculate byte offset: entryIndex * entrySize
            a.mul(a64::w6, a64::w5, a64::w3);  // w6 = entryIndex * entrySize

            // Load jump table data pointer
            a.ldr(a64::x7, a64::ptr(a64::x24, offsetof(JITHostFunctionTable, jumpTableData)));

            // Read entry based on entrySize
            // For now, support entry sizes 1, 2, 3, 4
            Label entrySize1 = a.new_label();
            Label entrySize2 = a.new_label();
            Label entrySize3 = a.new_label();
            Label entrySize4 = a.new_label();
            Label readDone = a.new_label();

            a.cmp(a64::w3, 1);
            a.b_eq(entrySize1);
            a.cmp(a64::w3, 2);
            a.b_eq(entrySize2);
            a.cmp(a64::w3, 3);
            a.b_eq(entrySize3);
            a.cmp(a64::w3, 4);
            a.b_eq(entrySize4);
            // Invalid entry size, fall back to interpreter
            a.b(unsupportedLabel);

            // Entry size 1: Read UInt8
            a.bind(entrySize1);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrb(a64::w0, a64::ptr(a64::x8));  // Load byte
            a.b(readDone);

            // Entry size 2: Read UInt16
            a.bind(entrySize2);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrh(a64::w0, a64::ptr(a64::x8));  // Load halfword
            a.b(readDone);

            // Entry size 3: Read UInt24
            a.bind(entrySize3);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldrb(a64::w0, a64::ptr(a64::x8));  // Load byte at offset 0
            a.ldrh(a64::w1, a64::ptr(a64::x8, 1));  // Load halfword at offset 1
            a.bfi(a64::w0, a64::w1, 8, 16);  // Insert w1 into w0 at bit 8
            a.b(readDone);

            // Entry size 4: Read UInt32
            a.bind(entrySize4);
            a.add(a64::x8, a64::x7, a64::x6);  // Calculate address: base + offset
            a.ldr(a64::w0, a64::ptr(a64::x8));  // Load word
            a.b(readDone);

            a.bind(readDone);

            // Update PC with the looked-up address
            a.mov(a64::w23, a64::w0);

            // Jump to the new PC
            // First, check if the new PC is within valid range
            a.cmp(a64::w0, codeSize);
            a.b_hs(pagefaultLabel);  // PC out of bounds

            // For now, fall back to interpreter with the updated PC
            // This is safe because the jump table lookup validated the target
            a.mov(a64::w0, 2);  // Exit code 2 = exit to interpreter with updated PC
            a.b(epilogueLabel);

            pc += 4;  // opcode + packed_regs + value + offset
            continue;
        }

        // === Ecalli (Host Call) ===
        // Ecalli format: [opcode][call_index_32bit] = 5 bytes
        if (opcode == 10) {  // Ecalli opcode is 10
            // Extract call_index from instruction bytes
            uint32_t call_index;
            memcpy(&call_index, &codeBuffer[pc + 1], 4);

            // Emit host call using the pvm_host_call_trampoline
            // ARM64 calling convention:
            // x0 = context (x24), x1 = func_idx, x2 = registers (x19),
            // x3 = memory (x20), x4 = memory_size (w21), x5 = gas (x22)
            a.mov(a64::x0, a64::x24);       // context pointer
            a.mov(a64::w1, call_index);      // function index
            a.mov(a64::x2, a64::x19);        // registers pointer
            a.mov(a64::x3, a64::x20);        // memory pointer
            a.mov(a64::w4, a64::w21);        // memory size
            a.mov(a64::x5, a64::x22);        // gas pointer

            // Call the trampoline
            a.mov(a64::x9, reinterpret_cast<uint64_t>(&pvm_host_call_trampoline));
            a.blr(a64::x9);

            // Check result (w0 contains error code or return value)
            // Any value >= 0xFFFF_FFFA is an error (hostRequestedHalt, pageFault, gasExhausted,
            // internalError, hostFunctionNotFound, hostFunctionThrewError, etc.)
            a.cmp(a64::w0, 0xFFFFFFFA);
            // Branch directly to epilogue to preserve error code in w0
            // This allows specific error codes to propagate:
            // - 0xFFFFFFFA (4294967290) = hostRequestedHalt
            // - 0xFFFFFFFB (4294967291) = pageFault
            // - 0xFFFFFFFC (4294967292) = gasExhausted
            // - 0xFFFFFFFD (4294967293) = internalError
            // - 0xFFFFFFFE (4294967294) = hostFunctionNotFound
            // - 0xFFFFFFFF (4294967295) = hostFunctionThrewError
            a.b_hs(epilogueLabel);  // Branch if Higher or Same (unsigned comparison) - preserves w0

            // Store result in R0
            a.str(a64::x0, a64::ptr(a64::x19, 0));

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::Trap)) {
            // Set return value to -1 (trap) in w0, then jump to epilogue
            a.mov(a64::w0, -1);
            a.b(epilogueLabel);
            pc += instrSize;
            continue;
        }

        // Opcode 1 (Halt/Fallthrough) is handled as normal instruction - just continues execution
        // Per spec, executing past program end will hit implicit Trap instructions

        // === Division Instructions with Zero-Check ===
        // Division by zero causes undefined behavior - must check explicitly
        // Format: [opcode][dest_reg][src_reg] = 3 bytes
        if (opcode_is(opcode, Opcode::DivU32) ||
            opcode_is(opcode, Opcode::DivS32) ||
            opcode_is(opcode, Opcode::RemU32) ||
            opcode_is(opcode, Opcode::RemS32) ||
            opcode_is(opcode, Opcode::DivU64) ||
            opcode_is(opcode, Opcode::DivS64) ||
            opcode_is(opcode, Opcode::RemU64) ||
            opcode_is(opcode, Opcode::RemS64)) {
            // Decode instruction: [opcode][dest_reg][src_reg]
            uint8_t dest_reg = codeBuffer[pc + 1];
            uint8_t src_reg = codeBuffer[pc + 2];

            // Load divisor into x1 for check
            a.ldr(a64::x1, a64::ptr(a64::x19, src_reg * 8));

            // Check if divisor is zero
            a.cmp(a64::x1, 0);
            a.b_eq(panicLabel);  // If zero, jump to panic (division by zero)

            // Not zero - proceed with division using dispatcher
            if (!jit_emitter_emit_basic_block_instructions(&a, "aarch64", codeBuffer, pc, pc + instrSize)) {
                return 3; // Compilation error
            }

            pc += instrSize;
            continue;
        }

        // === Load Instructions with Bounds Checking ===
        // PVM Spec: addresses < 2^16 (65536) → panic, addresses >= memory_size → page fault
        if (opcode_is(opcode, Opcode::LoadU8) ||
            opcode_is(opcode, Opcode::LoadI8) ||
            opcode_is(opcode, Opcode::LoadU16) ||
            opcode_is(opcode, Opcode::LoadI16) ||
            opcode_is(opcode, Opcode::LoadU32) ||
            opcode_is(opcode, Opcode::LoadI32) ||
            opcode_is(opcode, Opcode::LoadU64)) {
            // Decode instruction: [opcode][dest_reg][ptr_reg][offset_16bit]
            uint8_t dest_reg = codeBuffer[pc + 1];
            uint8_t ptr_reg = codeBuffer[pc + 2];
            int16_t offset;
            memcpy(&offset, &codeBuffer[pc + 3], 2);

            // Load pointer register into x0
            a.ldr(a64::x0, a64::ptr(a64::x19, ptr_reg * 8));

            // Add offset to get final address
            // ARM64 add immediate only supports 12-bit values (-4095 to 4095)
            // For larger offsets, load into temporary register (x5) and add
            // Note: x5 is safe to use here (invocation_context_ptr is in x24)
            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);  // Load offset into temporary register
                a.add(a64::x0, a64::x0, a64::x5);
            }

            // Bounds check: address < 65536 → panic
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // If we get here, address is valid - inline the load instruction
            // Load from memory into register, then store to VM register
            if (opcode_is(opcode, Opcode::LoadU8)) {
                a.ldrb(a64::w1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadI8)) {
                a.ldrsb(a64::x1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadU16)) {
                a.ldrh(a64::w1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadI16)) {
                a.ldrsh(a64::x1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadU32)) {
                a.ldr(a64::w1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadI32)) {
                a.ldrsw(a64::x1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            } else if (opcode_is(opcode, Opcode::LoadU64)) {
                a.ldr(a64::x1, a64::ptr(a64::x20, a64::x0));
                a.str(a64::x1, a64::ptr(a64::x19, dest_reg * 8));
            }

            pc += instrSize;
            continue;
        }

        // === Store Instructions with Bounds Checking ===
        if (opcode_is(opcode, Opcode::StoreU8) ||
            opcode_is(opcode, Opcode::StoreU16) ||
            opcode_is(opcode, Opcode::StoreU32) ||
            opcode_is(opcode, Opcode::StoreU64)) {
            // Decode instruction: [opcode][ptr_reg][src_reg][offset_16bit]
            uint8_t ptr_reg = codeBuffer[pc + 1];
            uint8_t src_reg = codeBuffer[pc + 2];
            int16_t offset;
            memcpy(&offset, &codeBuffer[pc + 3], 2);

            // Load pointer register into x0
            a.ldr(a64::x0, a64::ptr(a64::x19, ptr_reg * 8));

            // Add offset to get final address
            // ARM64 add immediate only supports 12-bit values (-4095 to 4095)
            // For larger offsets, load into temporary register (x5) and add
            // Note: x5 is safe to use here (invocation_context_ptr is in x24)
            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);  // Load offset into temporary register
                a.add(a64::x0, a64::x0, a64::x5);
            }

            // Bounds check: address < 65536 → panic
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // If we get here, address is valid - inline the store instruction
            // Load value from VM register, then store to memory
            a.ldr(a64::x1, a64::ptr(a64::x19, src_reg * 8));  // Load source value

            if (opcode_is(opcode, Opcode::StoreU8)) {
                a.strb(a64::w1, a64::ptr(a64::x20, a64::x0));
            } else if (opcode_is(opcode, Opcode::StoreU16)) {
                a.strh(a64::w1, a64::ptr(a64::x20, a64::x0));
            } else if (opcode_is(opcode, Opcode::StoreU32)) {
                a.str(a64::w1, a64::ptr(a64::x20, a64::x0));
            } else if (opcode_is(opcode, Opcode::StoreU64)) {
                a.str(a64::x1, a64::ptr(a64::x20, a64::x0));
            }

            pc += instrSize;
            continue;
        }

        // === StoreImm Instructions with Bounds Checking ===
        // PVM Spec: addresses < 2^16 (65536) → panic, addresses >= memory_size → page fault
        // Format: [opcode][value_Xbit][address_32bit]
        if (opcode_is(opcode, Opcode::StoreImmU8)) {
            // StoreImmU8: [opcode][value_8bit][address_32bit] = 6 bytes
            uint8_t value = codeBuffer[pc + 1];
            uint32_t address;
            memcpy(&address, &codeBuffer[pc + 2], 4);

            // Load address into x0 for bounds checking
            a.mov(a64::x0, address);

            // Bounds check: address < 65536 → panic (use b.lo for unsigned <)
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault (use b.hs for unsigned >=)
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // Store value to memory
            a.mov(a64::w8, value);
            a.strb(a64::w8, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU16)) {
            // StoreImmU16: [opcode][value_16bit][address_32bit] = 7 bytes
            uint16_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 2);
            memcpy(&address, &codeBuffer[pc + 3], 4);

            // Load address into x0 for bounds checking
            a.mov(a64::x0, address);

            // Bounds check: address < 65536 → panic
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // Store value to memory
            a.mov(a64::w8, value);
            a.strh(a64::w8, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU32)) {
            // StoreImmU32: [opcode][value_32bit][address_32bit] = 9 bytes
            uint32_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 4);
            memcpy(&address, &codeBuffer[pc + 5], 4);

            // Load address into x0 for bounds checking
            a.mov(a64::x0, address);

            // Bounds check: address < 65536 → panic
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // Store value to memory
            a.mov(a64::w8, value);
            a.str(a64::w8, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        if (opcode_is(opcode, Opcode::StoreImmU64)) {
            // StoreImmU64: [opcode][value_64bit][address_32bit] = 13 bytes
            uint64_t value;
            uint32_t address;
            memcpy(&value, &codeBuffer[pc + 1], 8);
            memcpy(&address, &codeBuffer[pc + 9], 4);

            // Load address into x0 for bounds checking
            a.mov(a64::x0, address);

            // Bounds check: address < 65536 → panic
            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            // Store value to memory
            a.mov(a64::x8, value);
            a.str(a64::x8, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // LoadImm: Load 32-bit immediate into register
        if (opcode_is(opcode, Opcode::LoadImm)) {
            // Per spec pvm.tex lines 327-334:
            // Format: [opcode][reg_index][immed_X (l_X bytes)]
            // where:
            //   ℓ = instruction length in bytes (from skip table)
            //   l_X = min(4, ℓ - 1)
            //   immed_X is sign-extended from l_X bytes to 64 bits
            //
            // Examples:
            //   ℓ=3 → l_X=2 → [opcode][reg][imm16] (3 bytes total)
            //   ℓ=4 → l_X=3 → [opcode][reg][imm24] (4 bytes total)
            //   ℓ=5+ → l_X=4 → [opcode][reg][imm32] (5+ bytes total)
            //
            // CRITICAL: ℓ comes from skip table, NOT from remaining bytecode length!

            // Get instruction length from skip table
            uint32_t instrLen = getInstrSize(pc);

            // Validate minimum length (opcode + register byte)
            if (instrLen < 2) {
                fprintf(stderr, "[JIT] LoadImm instruction too short at PC %u (length=%u)\n", pc, instrLen);
                return 3; // Compilation error
            }

            // Validate we have the full instruction in bytecode
            if (pc + instrLen > codeSize) {
                fprintf(stderr, "[JIT] LoadImm instruction truncated at PC %u (need %u bytes, have %zu)\n",
                        pc, instrLen, codeSize);
                return 3; // Compilation error
            }

            uint8_t destReg = codeBuffer[pc + 1];

            // Calculate l_X from instruction length per spec
            uint32_t l_X = (instrLen - 1 > 4) ? 4 : instrLen - 1;

            // Validate we have enough bytes for the immediate
            if (pc + 2 + l_X > codeSize) {
                fprintf(stderr, "[JIT] LoadImm immediate truncated at PC %u (l_X=%u)\n", pc, l_X);
                return 3; // Compilation error
            }

            // Load immediate value with l_X bytes
            uint32_t immediate = 0;
            memcpy(&immediate, &codeBuffer[pc + 2], l_X);

            // Sign-extend based on l_X
            if (l_X == 1) {
                immediate = int32_t(int8_t(immediate));
            } else if (l_X == 2) {
                immediate = int32_t(int16_t(immediate));
            } else if (l_X == 3) {
                // Sign-extend 24-bit to 32-bit
                if (immediate & 0x800000) {
                    immediate |= 0xFF000000;
                }
            }
            // l_X == 4: no sign-extension needed (already 32-bit)

            // LoadImm loads signed values and sign-extends to 64-bit
            a.mov(a64::w8, immediate);
            a.sxtw(a64::x8, a64::w8);  // Sign-extend w8 to x8
            a.str(a64::x8, a64::ptr(a64::x19, destReg * 8));  // Store to VM register array

            pc += instrLen;
            continue;
        }

        // LoadImmU64: Load 64-bit immediate into register
        if (opcode_is(opcode, Opcode::LoadImmU64)) {
            // LoadImmU64: [opcode][reg_index][value_64bit] = 10 bytes
            uint8_t destReg = codeBuffer[pc + 1];
            uint64_t immediate;
            memcpy(&immediate, &codeBuffer[pc + 2], 8);

            // Load 64-bit immediate using movz/movk sequence
            uint32_t imm0 = (immediate >> 0) & 0xFFFF;
            uint32_t imm1 = (immediate >> 16) & 0xFFFF;
            uint32_t imm2 = (immediate >> 32) & 0xFFFF;
            uint32_t imm3 = (immediate >> 48) & 0xFFFF;

            a.movz(a64::x8, imm0, 0);
            a.movk(a64::x8, imm1, 16);
            a.movk(a64::x8, imm2, 32);
            a.movk(a64::x8, imm3, 48);
            a.str(a64::x8, a64::ptr(a64::x19, destReg * 8));

            pc += instrSize;
            continue;
        }

        // Add64: 64-bit addition
        if (opcode_is(opcode, Opcode::Add64)) {
            // Add64: [opcode][ra|rb<<4][rd] = 4 bytes
            uint8_t ra = (codeBuffer[pc + 1] >> 0) & 0x0F;
            uint8_t rb = (codeBuffer[pc + 1] >> 4) & 0x0F;
            uint8_t rd = codeBuffer[pc + 2];

            // Load ra and rb
            a.ldr(a64::x0, a64::ptr(a64::x19, ra * 8));
            a.ldr(a64::x1, a64::ptr(a64::x19, rb * 8));

            // Add
            a.add(a64::x0, a64::x0, a64::x1);

            // Store to rd
            a.str(a64::x0, a64::ptr(a64::x19, rd * 8));

            pc += instrSize;
            continue;
        }

        // Sub64: 64-bit subtraction
        if (opcode_is(opcode, Opcode::Sub64)) {
            // Sub64: [opcode][ra|rb<<4][rd] = 4 bytes
            uint8_t ra = (codeBuffer[pc + 1] >> 0) & 0x0F;
            uint8_t rb = (codeBuffer[pc + 1] >> 4) & 0x0F;
            uint8_t rd = codeBuffer[pc + 2];

            // Load ra and rb
            a.ldr(a64::x0, a64::ptr(a64::x19, ra * 8));
            a.ldr(a64::x1, a64::ptr(a64::x19, rb * 8));

            // Subtract
            a.sub(a64::x0, a64::x0, a64::x1);

            // Store to rd
            a.str(a64::x0, a64::ptr(a64::x19, rd * 8));

            pc += instrSize;
            continue;
        }

        // StoreU64: Store 64-bit value from register to memory
        if (opcode_is(opcode, Opcode::StoreU64)) {
            // StoreU64: [opcode][reg_index][address_32bit] = 6 bytes
            uint8_t srcReg = codeBuffer[pc + 1];
            uint32_t address;
            memcpy(&address, &codeBuffer[pc + 2], 4);

            // Load address into x0 for bounds checking
            a.mov(a64::w0, address);

            // Bounds check: address < 65536 → panic
            a.cmp(a64::w0, 65536);
            a.b_lt(panicLabel);

            // Runtime check: address >= memory_size → page fault
            a.mov(a64::w1, a64::w21);  // Load memory_size into w1
            a.cmp(a64::w0, a64::w1);
            a.b_ge(pagefaultLabel);

            // Load source value from register
            a.ldr(a64::x1, a64::ptr(a64::x19, srcReg * 8));

            // Store to memory [VM_MEMORY_PTR + address]
            a.str(a64::x1, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // === LoadIndU32: Load 32-bit unsigned value from indirect address ===
        // Format: [opcode][ra_rb][offset_32bit] where ra_rb = (ra | rb << 4)
        if (opcode_is(opcode, Opcode::LoadIndU32)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::w1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndI32: Load 32-bit signed value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndI32)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldrsw(a64::x1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndU16: Load 16-bit unsigned value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndU16)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldrh(a64::w1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndI16: Load 16-bit signed value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndI16)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldrsh(a64::x1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndU8: Load 8-bit unsigned value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndU8)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldrb(a64::w1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndI8: Load 8-bit signed value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndI8)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldrsb(a64::x1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === LoadIndU64: Load 64-bit unsigned value from indirect address ===
        if (opcode_is(opcode, Opcode::LoadIndU64)) {
            uint8_t ra_rb = codeBuffer[pc + 1];
            uint8_t ra = (ra_rb >> 0) & 0x0F;
            uint8_t rb = (ra_rb >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, rb * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::x1, a64::ptr(a64::x20, a64::x0));

            a.str(a64::x1, a64::ptr(a64::x19, ra * 8));

            pc += instrSize;
            continue;
        }

        // === StoreIndU8: Store 8-bit value to indirect address ===
        // Format: [opcode][src_dest][offset_32bit] where src_dest = (src | dest << 4)
        if (opcode_is(opcode, Opcode::StoreIndU8)) {
            uint8_t src_dest = codeBuffer[pc + 1];
            uint8_t src = (src_dest >> 0) & 0x0F;
            uint8_t dest = (src_dest >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, dest * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::x1, a64::ptr(a64::x19, src * 8));

            a.strb(a64::w1, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // === StoreIndU16: Store 16-bit value to indirect address ===
        if (opcode_is(opcode, Opcode::StoreIndU16)) {
            uint8_t src_dest = codeBuffer[pc + 1];
            uint8_t src = (src_dest >> 0) & 0x0F;
            uint8_t dest = (src_dest >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, dest * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::x1, a64::ptr(a64::x19, src * 8));

            a.strh(a64::w1, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // === StoreIndU32: Store 32-bit value to indirect address ===
        if (opcode_is(opcode, Opcode::StoreIndU32)) {
            uint8_t src_dest = codeBuffer[pc + 1];
            uint8_t src = (src_dest >> 0) & 0x0F;
            uint8_t dest = (src_dest >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, dest * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::x1, a64::ptr(a64::x19, src * 8));

            a.str(a64::w1, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // === StoreIndU64: Store 64-bit value to indirect address ===
        if (opcode_is(opcode, Opcode::StoreIndU64)) {
            uint8_t src_dest = codeBuffer[pc + 1];
            uint8_t src = (src_dest >> 0) & 0x0F;
            uint8_t dest = (src_dest >> 4) & 0x0F;
            uint32_t offset;
            memcpy(&offset, &codeBuffer[pc + 2], 4);

            a.ldr(a64::x0, a64::ptr(a64::x19, dest * 8));

            if (offset >= -4095 && offset <= 4095) {
                a.add(a64::x0, a64::x0, offset);
            } else {
                a.mov(a64::x5, offset);
                a.add(a64::x0, a64::x0, a64::x5);
            }

            a.cmp(a64::x0, 65536);
            a.b_lo(panicLabel);

            a.mov(a64::w1, a64::w21);
            a.cmp(a64::x0, a64::x1);
            a.b_hs(pagefaultLabel);

            a.ldr(a64::x1, a64::ptr(a64::x19, src * 8));

            a.str(a64::x1, a64::ptr(a64::x20, a64::x0));

            pc += instrSize;
            continue;
        }

        // For all other instructions, use the existing dispatcher
        if (!jit_emitter_emit_basic_block_instructions(&a, "aarch64", codeBuffer, pc, pc + instrSize)) {
            return 3; // Compilation error
        }

        pc += instrSize;
    }

    // Bind panic label
    a.bind(panicLabel);
    a.mov(a64::w0, -1);  // Exit code -1 = panic(.trap)
    a.b(epilogueLabel);

    // Bind pagefault label
    // Note: Faulting address should be in x0 (from bounds checking code)
    // Save it to VM register R0 before setting exit code
    a.bind(pagefaultLabel);
    a.str(a64::x0, a64::ptr(a64::x19, 0));  // Save faulting address to VM R0
    a.mov(a64::w0, 3);   // Exit code 3 = pageFault
    a.b(epilogueLabel);

    // Bind out-of-gas label
    a.bind(outOfGasLabel);
    a.mov(a64::w0, 1);   // Exit code 1 = outOfGas
    a.b(epilogueLabel);

    // Bind exit label
    a.bind(exitLabel);

    // Set return value to 0 (halt) in w0
    a.mov(a64::w0, 0);

    // Bind epilogue label (for Trap - already has w0=-1 set)
    a.bind(epilogueLabel);

    // Epilogue: restore callee-saved registers and return
    a.ldp(x29, x30, ptr(a64::sp, 80));
    a.ldp(x27, x28, ptr(a64::sp, 64));
    a.ldp(x25, x26, ptr(a64::sp, 48));
    a.ldp(x23, x24, ptr(a64::sp, 32));
    a.ldp(x21, x22, ptr(a64::sp, 16));
    a.ldp(x19, x20, ptr(a64::sp, 0));
    a.add(a64::sp, a64::sp, 16 * 10);
    a.ret(x30);

    // Generate the function code
    Error addErr = ctx->runtime->add(funcOut, &code);
    if (addErr != kErrorOk) {
        return int32_t(addErr);
    }

    return 0; // Success
}
